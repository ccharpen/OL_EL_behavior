%This script performs all the model-fitting analyses for Study 2, and 
%generates the results presented in Table 1 (AIC, Frequency, Nbest),
%as well as the plots presented in Figure S6C

clear all
close all
fs = filesep;

data_dir = ['..' fs '..' fs 'data'];
mod_dir = ['..' fs 'dependencies' fs 'model_functions']; %directory where modelling functions are saved (common to both studies)

addpath(['..' fs 'dependencies' fs 'cbm-master' fs 'codes']);
addpath(['..' fs 'dependencies' fs 'plotSpread']);
addpath(mod_dir); 

%load data and format data as needed (in cell array)
data = readtable([data_dir fs 'data_study2.csv']);
subID_list = unique(data.subNb);
n_all = length(subID_list);
data_all = cell(n_all,1);
for s=1:n_all
    subNb = subID_list(s);
    data_all{s} = table2array(data(data.subNb==subNb,2:end));
end

%specify loglikelihood functions
func_list = {@LL_Baseline; @LL_ExpLearn; @LL_ObsLearn; @LL_FixArb; @LL_DynArb};
n_mod = length(func_list);

%specify output files
out_dir = 'model_fitting_outputs';
if ~exist(out_dir, 'dir')
   mkdir(out_dir)
end
out_fname_list = {'lap_Baseline.mat';'lap_ExpLearn.mat';'lap_ObsLearn.mat';...
    'lap_FixArb.mat';'lap_DynArb.mat'};

mod_names = {'Baseline'; 'ExpLearn'; 'ObsLearn'; 'FixArb'; 'DynArb'};

%number of parameters for each model
np = [4;3;2;6;6]; 

%specify parameter priors
v = 6.25; %parameter variance (6.25 is large enough to cover a wide range of parameters with no excessive penalty)

%% Individual-level fits
%run cbm_lap for each model
%this will fit every model to each subject's data separately (ie in a
%non-hierarchical fashion), using Laplace approximation, which needs a
%normal prior for every parameter
numcores = feature('numcores');
parfor (m=1:n_mod,numcores-1) 
    prior = struct('mean',zeros(np(m),1),'variance',v);
    cbm_lap(data_all, func_list{m}, prior, [out_dir fs out_fname_list{m}]);
end

%transform parameters and calculate model fitting metrics
fitRecap = struct();
fitRecap.pseudoR2 = table('Size',[n_all n_mod],'VariableTypes',repmat({'double'},1,n_mod),'VariableNames',mod_names);
fitRecap.AIC = table('Size',[n_all n_mod],'VariableTypes',repmat({'double'},1,n_mod),'VariableNames',mod_names);
fitRecap.BIC = table('Size',[n_all n_mod],'VariableTypes',repmat({'double'},1,n_mod),'VariableNames',mod_names);
fitRecap.LHsub = table('Size',[n_all n_mod],'VariableTypes',repmat({'double'},1,n_mod),'VariableNames',mod_names);
fitRecap.corrsub = table('Size',[n_all n_mod],'VariableTypes',repmat({'double'},1,n_mod),'VariableNames',mod_names);
for m=1:n_mod
    fname = [out_dir fs out_fname_list{m}];
    load(fname,'cbm')
    params = cbm.output.parameters;
    npar = np(m);
    
    cbm.output.paramTrans = params;
    if m>=2
        cbm.output.paramTrans(:,1) = exp(params(:,1));
    end
    if m==2 || m==3 %single strategy model (one learning rate)
        cbm.output.paramTrans(:,2) = 1./(1+exp(-params(:,2)));        
    elseif m>=4 %arbitration models (second beta + 2 learning rates)    
        cbm.output.paramTrans(:,2) = exp(params(:,2));
        cbm.output.paramTrans(:,3) = 1./(1+exp(-params(:,3)));
        cbm.output.paramTrans(:,4) = 1./(1+exp(-params(:,4)));
    end
    if m==4 %FixArb model (weight from 0-1)
        cbm.output.paramTrans(:,5) = 1./(1+exp(-params(:,5)));
    end
    
    for s=1:n_all
        subNb = subID_list(s);
        P = table2array(data(data.subNb==subNb,2:end));
        ntg = sum(P(:,19)==0);
        [ll,P_pred] = func_list{m}(params(s,:),P);
        %calculate model
        cbm.output.pseudoR2(s,1) = 1 - ll/(ntg*log(0.5));
        cbm.output.BIC(s,1) = -2*ll + log(ntg)*npar;
        cbm.output.AIC(s,1) = -2*ll + 2*npar;
        if cbm.output.pseudoR2(s,1)<0
            cbm.output.pseudoR2(s,1)=0;
        end
        %using values generated by LL function
        cbm.output.LHsub(s,1) = nanmean(P_pred(:,1));
        cbm.output.corrsub(s,1) = nanmean(P_pred(:,3));   
    end
    save(fname,'cbm')
    
    fitRecap.pseudoR2{:,m} = cbm.output.pseudoR2;
    fitRecap.AIC{:,m}      = cbm.output.AIC;
    fitRecap.BIC{:,m}      = cbm.output.BIC;
    fitRecap.LHsub{:,m}    = cbm.output.LHsub;
    fitRecap.corrsub{:,m}  = cbm.output.corrsub;
    
    fitRecap.paramRaw.(mod_names{m}) = cbm.output.parameters;
    fitRecap.paramTrans.(mod_names{m}) = cbm.output.paramTrans;
    
end
save([out_dir fs 'Recap_model_fitting.mat'],'fitRecap');

%AIC values reported in Table 1:
AIC_values = mean(table2array(fitRecap.AIC))

%% Hierarchical fits on single models
fname_hbi = {'hbi_Baseline.mat';'hbi_ExpLearn.mat';'hbi_ObsLearn.mat';'hbi_FixArb.mat';'hbi_DynArb.mat'};
parfor (m=1:n_mod,numcores-1) 
    cbm_hbi(data_all, func_list(m), {[out_dir fs out_fname_list{m}]}, [out_dir fs fname_hbi{m}]);
end

%calculate AIC and other measures based on hierarchical fits
hfitRecap = struct();
hfitRecap.pseudoR2 = table('Size',[n_all n_mod],'VariableTypes',repmat({'double'},1,n_mod),'VariableNames',mod_names);
hfitRecap.AIC = table('Size',[n_all n_mod],'VariableTypes',repmat({'double'},1,n_mod),'VariableNames',mod_names);
hfitRecap.BIC = table('Size',[n_all n_mod],'VariableTypes',repmat({'double'},1,n_mod),'VariableNames',mod_names);
hfitRecap.LHsub = table('Size',[n_all n_mod],'VariableTypes',repmat({'double'},1,n_mod),'VariableNames',mod_names);
hfitRecap.corrsub = table('Size',[n_all n_mod],'VariableTypes',repmat({'double'},1,n_mod),'VariableNames',mod_names);
for m=1:n_mod
    fname = [out_dir fs fname_hbi{m}];
    load(fname,'cbm')
    params = cbm.output.parameters{:};
    npar = np(m);
    
    cbm.output.paramTrans = params;
    if m>=2
        cbm.output.paramTrans(:,1) = exp(params(:,1));
    end
    if m==2 || m==3 %single strategy model (one learning rate)
        cbm.output.paramTrans(:,2) = 1./(1+exp(-params(:,2)));        
    elseif m>=4 %arbitration models (second beta + 2 learning rates)    
        cbm.output.paramTrans(:,2) = exp(params(:,2));
        cbm.output.paramTrans(:,3) = 1./(1+exp(-params(:,3)));
        cbm.output.paramTrans(:,4) = 1./(1+exp(-params(:,4)));
    end
    if m==4 %FixArb model (weight from 0-1)
        cbm.output.paramTrans(:,5) = 1./(1+exp(-params(:,5)));
    end
    
    for s=1:n_all
        subNb = subID_list(s);
        P = table2array(data(data.subNb==subNb,2:end));
        ntg = sum(P(:,19)==0);
        [ll,P_pred] = func_list{m}(params(s,:),P);
        %calculate model
        cbm.output.pseudoR2(s,1) = 1 - ll/(ntg*log(0.5));
        cbm.output.BIC(s,1) = -2*ll + log(ntg)*npar;
        cbm.output.AIC(s,1) = -2*ll + 2*npar;
        if cbm.output.pseudoR2(s,1)<0
            cbm.output.pseudoR2(s,1)=0;
        end
        %using values generated by LL function
        cbm.output.LHsub(s,1) = nanmean(P_pred(:,1));
        cbm.output.corrsub(s,1) = nanmean(P_pred(:,3));   
    end
    save(fname,'cbm')
    
    hfitRecap.pseudoR2{:,m} = cbm.output.pseudoR2;
    hfitRecap.AIC{:,m}      = cbm.output.AIC;
    hfitRecap.BIC{:,m}      = cbm.output.BIC;
    hfitRecap.LHsub{:,m}    = cbm.output.LHsub;
    hfitRecap.corrsub{:,m}  = cbm.output.corrsub;
    
    hfitRecap.paramRaw.(mod_names{m}) = cbm.output.parameters;
    hfitRecap.paramTrans.(mod_names{m}) = cbm.output.paramTrans;
end
save([out_dir fs 'Recap_model_fitting.mat'],'fitRecap','hfitRecap');


%% Hierarchical fitting across all 5 models
models = {@LL_Baseline; @LL_ExpLearn; @LL_ObsLearn; @LL_FixArb; @LL_DynArb};
fcbm_maps = {'lap_Baseline.mat';'lap_ExpLearn.mat';'lap_ObsLearn.mat';...
    'lap_FixArb.mat';'lap_DynArb.mat'};
fname_hbi = 'hbi_5mods.mat';
cd(out_dir)
cbm_hbi(data_all, models, fcbm_maps, fname_hbi);
cd ..
%the model frequency values reported in Table 1 can be found in
%hbi_5mods.mat output file, in variable cbm.output.model_frequency

%define groups based on hierarchical fit model responsibility values
load(['model_fitting_outputs' fs 'hbi_5mods.mat'])
hfit_recap = cbm.output.responsibility;
for s=1:n_all
    hfit_recap(s,6) = find(hfit_recap(s,1:5)==max(hfit_recap(s,1:5)));
end
group = hfit_recap(:,6);
gsize = [sum(group==1) sum(group==2) sum(group==3) sum(group==4) sum(group==5)];
gdist = gsize/sum(gsize);
save('Recap_model_fitting.mat','fitRecap','hfitRecap','group');
%gsize and gdist contain the values reported in the Nbest column of Table 1

%% Extract trial-by-trial arbitration weight and plot mean per condition (Figure S6C)
ntr = 160;
w_bd = nan(n_all, 8);
for s=1:n_all
    params_dynarb = fitRecap.paramRaw.DynArb(s,:);
    subNb = subID_list(s);
    P = table2array(data(data.subNb==subNb,2:end));
    P_pred = generate_choice_DynArb(params_dynarb, P);
    w = P_pred(:,25);
    
    %define uncertainty condition based on key trials, instead of design conditions
    %OL unc = low if past 2 box-token transition consistent; high if not
    %EL unc = low if W-st-W, W-sw-0, 0-st-0, 0-sw-W; high otherwise
    %RM = high if >25, low otherwise
    OL_lu = zeros(ntr,1);
    EL_lu = zeros(ntr,1);
    RM_h = zeros(ntr,1);
    outc_bin = P(:,18); outc_bin(outc_bin>0)=1;
    for t=1:ntr
        if P(t,4)>=3
            if P(t-1,6)==P(t,6)
                OL_lu(t) = 1;
            end
            if (outc_bin(t-2)==outc_bin(t-1) && P(t-2,14)==P(t-1,14)) || (outc_bin(t-2)~=outc_bin(t-1) && P(t-2,14)~=P(t-1,14))
                %same choice, same outcome OR different choice, different outcome
                EL_lu(t) = 1;
            end
        end
        if P(t,3)>=2 && P(t-1,18)>25
            RM_h(t) = 1;
        end
    end
    OL_lu = logical(OL_lu);
    EL_lu = logical(EL_lu);
    RM_h = logical(RM_h);
    
    w_bd(s,:) = [nanmean(w(OL_lu & EL_lu & RM_h)) nanmean(w(OL_lu & EL_lu & ~RM_h)) ...
        nanmean(w(OL_lu & ~EL_lu & RM_h)) nanmean(w(OL_lu & ~EL_lu & ~RM_h)) ...
        nanmean(w(~OL_lu & EL_lu & RM_h)) nanmean(w(~OL_lu & EL_lu & ~RM_h)) ...
        nanmean(w(~OL_lu & ~EL_lu & RM_h)) nanmean(w(~OL_lu & ~EL_lu & ~RM_h))];  
end

figure;
subplot(1,2,1); hold on
b = bar([nanmean(w_bd(:,1:2)); nanmean(w_bd(:,3:4))],0.8,'FaceColor','flat','EdgeColor','k','LineWidth',1);
b(1).CData = [0.9290 0.6940 0.1250]; 
b(2).CData = [0.4940 0.1840 0.5560];
plotSpread(w_bd(:,1:4),'xValues',[0.85 1.15 1.85 2.15],'distributionColors',[0.4 0.4 0.4]); 
errorbar([0.85 1.15 1.85 2.15],nanmean(w_bd(:,1:4)),nanstd(w_bd(:,1:4))/sqrt(n_all),'.k','LineWidth',1.5)
plot([0.5 2.5],[0.5 0.5],'--k')
xticks([1 2])
xticklabels({'Low','High'})
xlabel('EL uncertainty')
ylabel('Arbitration weight (OL vs EL)')
title('LOW OL uncertainty')
subplot(1,2,2); hold on
b = bar([nanmean(w_bd(:,5:6)); nanmean(w_bd(:,7:8))],0.8,'FaceColor','flat','EdgeColor','k','LineWidth',1);
b(1).CData = [0.9290 0.6940 0.1250]; 
b(2).CData = [0.4940 0.1840 0.5560];
plotSpread(w_bd(:,5:8),'xValues',[0.85 1.15 1.85 2.15],'distributionColors',[0.4 0.4 0.4]); 
errorbar([0.85 1.15 1.85 2.15],nanmean(w_bd(:,5:8)),nanstd(w_bd(:,5:8))/sqrt(n_all),'.k','LineWidth',1.5)
plot([0.5 2.5],[0.5 0.5],'--k')
xticks([1 2])
xticklabels({'Low','High'})
xlabel('EL uncertainty')
title('HIGH OL uncertainty')
leg = legend({'High','Low'});
title(leg,'Magnitude')
