clear all
close all
fs = filesep;

data_dir = ['..' fs '..' fs 'data'];
mod_dir = ['..' fs 'dependencies' fs 'model_functions']; %directory where modelling functions are saved (common to both studies)

addpath(['..' fs 'dependencies' fs 'cbm-master' fs 'codes']);
addpath(['..' fs 'dependencies' fs 'plotSpread']);
addpath(mod_dir); 

%load data and format data as needed (in cell array)
data = readtable([data_dir fs 'data_study2.csv']);
subID_list = unique(data.subNb);
n_all = length(subID_list);
data_all = cell(n_all,1);
for s=1:n_all
    subNb = subID_list(s);
    data_all{s} = table2array(data(data.subNb==subNb,2:end));
end

%specify loglikelihood functions
func_list = {@LL_Baseline; @LL_ExpLearn; @LL_ObsLearn; @LL_FixArb; @LL_DynArb};
n_mod = length(func_list);

%specify output files
out_dir = 'model_fitting_outputs';
if ~exist(out_dir, 'dir')
   mkdir(out_dir)
end
out_fname_list = {'lap_Baseline.mat';'lap_ExpLearn.mat';'lap_ObsLearn.mat';...
    'lap_FixArb.mat';'lap_DynArb.mat'};

mod_names = {'Baseline'; 'ExpLearn'; 'ObsLearn'; 'FixArb'; 'DynArb'};

%number of parameters for each model
np = [4;3;2;6;6]; 

%specify parameter priors
v = 6.25; %parameter variance (6.25 is large enough to cover a wide range of parameters with no excessive penalty)

%% Individual-level fits
%run cbm_lap for each model
%this will fit every model to each subject's data separately (ie in a
%non-hierarchical fashion), using Laplace approximation, which needs a
%normal prior for every parameter
numcores = feature('numcores');
parfor (m=1:n_mod,numcores-1) 
    prior = struct('mean',zeros(np(m),1),'variance',v);
    cbm_lap(data_all, func_list{m}, prior, [out_dir fs out_fname_list{m}]);
end

%transform parameters and calculate model fitting metrics
fitRecap = struct();
fitRecap.pseudoR2 = table('Size',[n_all n_mod],'VariableTypes',repmat({'double'},1,n_mod),'VariableNames',mod_names);
fitRecap.AIC = table('Size',[n_all n_mod],'VariableTypes',repmat({'double'},1,n_mod),'VariableNames',mod_names);
fitRecap.BIC = table('Size',[n_all n_mod],'VariableTypes',repmat({'double'},1,n_mod),'VariableNames',mod_names);
fitRecap.LHsub = table('Size',[n_all n_mod],'VariableTypes',repmat({'double'},1,n_mod),'VariableNames',mod_names);
fitRecap.corrsub = table('Size',[n_all n_mod],'VariableTypes',repmat({'double'},1,n_mod),'VariableNames',mod_names);
for m=1:n_mod
    fname = [out_dir fs out_fname_list{m}];
    load(fname,'cbm')
    params = cbm.output.parameters;
    npar = np(m);
    
    cbm.output.paramTrans = params;
    if m>=2
        cbm.output.paramTrans(:,1) = exp(params(:,1));
    end
    if m==2 || m==3 %single strategy model (one learning rate)
        cbm.output.paramTrans(:,2) = 1./(1+exp(-params(:,2)));        
    elseif m>=4 %arbitration models (second beta + 2 learning rates)    
        cbm.output.paramTrans(:,2) = exp(params(:,2));
        cbm.output.paramTrans(:,3) = 1./(1+exp(-params(:,3)));
        cbm.output.paramTrans(:,4) = 1./(1+exp(-params(:,4)));
    end
    if m==4 %FixArb model (weight from 0-1)
        cbm.output.paramTrans(:,5) = 1./(1+exp(-params(:,5)));
    end
    
    for s=1:n_all
        subNb = subID_list(s);
        P = table2array(data(data.subNb==subNb,2:end));
        ntg = sum(P(:,19)==0);
        [ll,P_pred] = func_list{m}(params(s,:),P);
        %calculate model
        cbm.output.pseudoR2(s,1) = 1 - ll/(ntg*log(0.5));
        cbm.output.BIC(s,1) = -2*ll + log(ntg)*npar;
        cbm.output.AIC(s,1) = -2*ll + 2*npar;
        if cbm.output.pseudoR2(s,1)<0
            cbm.output.pseudoR2(s,1)=0;
        end
        %using values generated by LL function
        cbm.output.LHsub(s,1) = nanmean(P_pred(:,1));
        cbm.output.corrsub(s,1) = nanmean(P_pred(:,3));   
    end
    save(fname,'cbm')
    
    fitRecap.pseudoR2{:,m} = cbm.output.pseudoR2;
    fitRecap.AIC{:,m}      = cbm.output.AIC;
    fitRecap.BIC{:,m}      = cbm.output.BIC;
    fitRecap.LHsub{:,m}    = cbm.output.LHsub;
    fitRecap.corrsub{:,m}  = cbm.output.corrsub;
    
    fitRecap.paramRaw.(mod_names{m}) = cbm.output.parameters;
    fitRecap.paramTrans.(mod_names{m}) = cbm.output.paramTrans;
    
end
save([out_dir fs 'Recap_model_fitting.mat'],'fitRecap');

%% Hierarchical fits on single models
fname_hbi = {'hbi_Baseline.mat';'hbi_ExpLearn.mat';'hbi_ObsLearn.mat';'hbi_FixArb.mat';'hbi_DynArb.mat'};
parfor (m=1:n_mod,numcores-1) 
    cbm_hbi(data_all, func_list(m), {[out_dir fs out_fname_list{m}]}, [out_dir fs fname_hbi{m}]);
end

%calculate AIC and other measures based on hierarchical fits
hfitRecap = struct();
hfitRecap.pseudoR2 = table('Size',[n_all n_mod],'VariableTypes',repmat({'double'},1,n_mod),'VariableNames',mod_names);
hfitRecap.AIC = table('Size',[n_all n_mod],'VariableTypes',repmat({'double'},1,n_mod),'VariableNames',mod_names);
hfitRecap.BIC = table('Size',[n_all n_mod],'VariableTypes',repmat({'double'},1,n_mod),'VariableNames',mod_names);
hfitRecap.LHsub = table('Size',[n_all n_mod],'VariableTypes',repmat({'double'},1,n_mod),'VariableNames',mod_names);
hfitRecap.corrsub = table('Size',[n_all n_mod],'VariableTypes',repmat({'double'},1,n_mod),'VariableNames',mod_names);
for m=1:n_mod
    fname = [out_dir fs fname_hbi{m}];
    load(fname,'cbm')
    params = cbm.output.parameters{:};
    npar = np(m);
    
    cbm.output.paramTrans = params;
    if m>=2
        cbm.output.paramTrans(:,1) = exp(params(:,1));
    end
    if m==2 || m==3 %single strategy model (one learning rate)
        cbm.output.paramTrans(:,2) = 1./(1+exp(-params(:,2)));        
    elseif m>=4 %arbitration models (second beta + 2 learning rates)    
        cbm.output.paramTrans(:,2) = exp(params(:,2));
        cbm.output.paramTrans(:,3) = 1./(1+exp(-params(:,3)));
        cbm.output.paramTrans(:,4) = 1./(1+exp(-params(:,4)));
    end
    if m==4 %FixArb model (weight from 0-1)
        cbm.output.paramTrans(:,5) = 1./(1+exp(-params(:,5)));
    end
    
    for s=1:n_all
        subNb = subID_list(s);
        P = table2array(data(data.subNb==subNb,2:end));
        ntg = sum(P(:,19)==0);
        [ll,P_pred] = func_list{m}(params(s,:),P);
        %calculate model
        cbm.output.pseudoR2(s,1) = 1 - ll/(ntg*log(0.5));
        cbm.output.BIC(s,1) = -2*ll + log(ntg)*npar;
        cbm.output.AIC(s,1) = -2*ll + 2*npar;
        if cbm.output.pseudoR2(s,1)<0
            cbm.output.pseudoR2(s,1)=0;
        end
        %using values generated by LL function
        cbm.output.LHsub(s,1) = nanmean(P_pred(:,1));
        cbm.output.corrsub(s,1) = nanmean(P_pred(:,3));   
    end
    save(fname,'cbm')
    
    hfitRecap.pseudoR2{:,m} = cbm.output.pseudoR2;
    hfitRecap.AIC{:,m}      = cbm.output.AIC;
    hfitRecap.BIC{:,m}      = cbm.output.BIC;
    hfitRecap.LHsub{:,m}    = cbm.output.LHsub;
    hfitRecap.corrsub{:,m}  = cbm.output.corrsub;
    
    hfitRecap.paramRaw.(mod_names{m}) = cbm.output.parameters;
    hfitRecap.paramTrans.(mod_names{m}) = cbm.output.paramTrans;
end
save([out_dir fs 'Recap_model_fitting.mat'],'fitRecap','hfitRecap');


%% Hierarchical fitting across all 5 models
models = {@LL_Baseline; @LL_ExpLearn; @LL_ObsLearn; @LL_FixArb; @LL_DynArb};
fcbm_maps = {'lap_Baseline.mat';'lap_ExpLearn.mat';'lap_ObsLearn.mat';...
    'lap_FixArb.mat';'lap_DynArb.mat'};
fname_hbi = 'hbi_5mods.mat';
cd(out_dir)
cbm_hbi(data_all, models, fcbm_maps, fname_hbi);
cd ..

%% check that OL vs EL models predict corresponding behavioral signature
ntr = 160;
nt_diff_from_OL_sub = nan(n_all,1);
prop_OL_ch_from_OL_sub = nan(n_all,1);
nt_diff_from_EL_sub = nan(n_all,1);
prop_OL_ch_from_EL_sub = nan(n_all,1);
for s=1:n_all
    params_OL = fitRecap.paramRaw.ObsLearn(s,:);
    params_EL = fitRecap.paramRaw.ExpLearn(s,:);
    subNb = subID_list(s);
    P = table2array(data(data.subNb==subNb,2:end));
    
    %run 1000 iterations to account for stochasticity in choice-generation process
    nt_diff_from_OL = nan(1000,1);
    nt_diff_from_EL = nan(1000,1);
    prop_OL_ch_from_OL = nan(1000,1);
    prop_OL_ch_from_EL = nan(1000,1);
    
    for i=1:1000
    
        %predict choice from OL model
        P_pred_OL = generate_choice_ObsLearn(params_OL, P);
        pred_ch_OL = P_pred_OL(:,4);
        
        %predict choice from EL model
        P_pred_EL = generate_choice_ExpLearn(params_EL, P);
        pred_token = P_pred_EL(:,5);
        pred_outc = P_pred_EL(:,7);
        pred_ch_EL = P_pred_EL(:,4);
        
        %define behavioral signature of OL and EL:
        %OL: whether partner's most recent choice led to an orange (1) or blue (-1) token
        past_act = nan(ntr,1);
        %EL: whether most recent token was rewarded (1) or not (-1)
        past_tok = nan(ntr,1);   
        for t=1:ntr
            %calculate whether partner's most recent choice led to orange (1)
            %or blue (-1) token and whether the most recent token was rewarded
            %or not + whether subject choice is consistent with EL and/or OL
            if P(t,4)==1
                if P(t,11)==1 %orange token obtained by partner
                    past_act(t)=1;
                elseif P(t,11)==2 %blue token obtained by partner
                    past_act(t)=-1;
                end
            else
                if (P(t-1,11)==1 && P(t,9)==P(t-1,9)) || (P(t-1,11)==2 && P(t,9)~=P(t-1,9))
                    %if partner got orange token on previous trial and repeats same choice
                    %or if partner got blue token on previous trial and switched choice
                    past_act(t)=1;
                elseif (P(t-1,11)==2 && P(t,9)==P(t-1,9)) || (P(t-1,11)==1 && P(t,9)~=P(t-1,9))
                    %if partner got blue token on previous trial and repeats same choice
                    %or if partner got orange token on previous trial and switched choice
                    past_act(t)=-1;
                end
            end
            if t==1 %no past token evidence on trial 1
                past_tok(t) = 0; 
            else
                if (pred_token(t-1)==1 && pred_outc(t-1)>0) || (pred_token(t-1)==2 && pred_outc(t-1)==0)
                    %past orange token was rewarded or past blue token was not
                    past_tok(t)=1;
                elseif (pred_token(t-1)==2 && pred_outc(t-1)>0) || (pred_token(t-1)==1 && pred_outc(t-1)==0)
                    %past blue token was rewarded or past orange token was not
                    past_tok(t)=-1;
                end
            end
        end
    
        %define trials consistent with OL and with EL from OL-predicted choices   
        ch_OL_from_OL = (past_act==1 & past_tok==-1 & pred_ch_OL==1) | (past_act==-1 & past_tok==1 & pred_ch_OL==0);
        ch_EL_from_OL = (past_act==1 & past_tok==-1 & pred_ch_OL==0) | (past_act==-1 & past_tok==1 & pred_ch_OL==1);
        ind_diff_from_OL = ch_OL_from_OL | ch_EL_from_OL; %trials where OL and EL make different predictions
        nt_diff_from_OL(i,1) = sum(ind_diff_from_OL);
        prop_OL_ch_from_OL(i,1) = mean(ch_OL_from_OL(ind_diff_from_OL));

        %define trials consistent with OL and with EL from EL-predicted choices   
        ch_OL_from_EL = (past_act==1 & past_tok==-1 & pred_ch_EL==1) | (past_act==-1 & past_tok==1 & pred_ch_EL==0);
        ch_EL_from_EL = (past_act==1 & past_tok==-1 & pred_ch_EL==0) | (past_act==-1 & past_tok==1 & pred_ch_EL==1);
        ind_diff_from_EL = ch_OL_from_EL | ch_EL_from_EL; %trials where OL and EL make different predictions
        nt_diff_from_EL(i,1) = sum(ind_diff_from_EL);
        prop_OL_ch_from_EL(i,1) = mean(ch_OL_from_EL(ind_diff_from_EL));
    end
    nt_diff_from_OL_sub(s,1) = mean(nt_diff_from_OL);
    prop_OL_ch_from_OL_sub(s,1) = mean(prop_OL_ch_from_OL);
    nt_diff_from_EL_sub(s,1) = mean(nt_diff_from_EL);
    prop_OL_ch_from_EL_sub(s,1) = mean(prop_OL_ch_from_EL);
end
%load Behavioral variables to compare with model predictions
load('Behavioral_variables.mat')

%plot histograms of model predictions and data
figure;
subplot(2,1,1); hold on
histogram(prop_OL_ch_from_EL_sub,23,'FaceAlpha',0.6);
histogram(prop_OL_ch_from_OL_sub,15,'FaceAlpha',0.6);
set(gca,'box','off')
xlim([0.1 0.9])
ylabel('count')
l = legend({'EL model','OL model'});
title(l,'predicted by:')
title('Model predictions')
subplot(2,1,2);
histogram(Behavior.Prop_OL_ch(:,1),30,'FaceColor',[0.5 0.5 0.5]);
set(gca,'box','off')
xlim([0.1 0.9])
ylabel('count')
xlabel('proportion of choices consistent with OL (vs EL)')
title('Data')

%plot correlations between data and model predictions
iEL = Behavior.Prop_OL_ch(:,1)<0.5;
iOL = Behavior.Prop_OL_ch(:,1)>0.5;
figure;
subplot(1,2,1); hold on
plot(Behavior.Prop_OL_ch(iEL,1),prop_OL_ch_from_EL_sub(iEL),'.','Color','#0072BD'); lsline()
plot(Behavior.Prop_OL_ch(iEL,1),prop_OL_ch_from_OL_sub(iEL),'.','Color','#D95319'); lsline()
xlim([0.1 0.5]); ylim([0.1 0.9])
title({'Experiential learners'; '(OL choice prop. < 0.5)'})
xlabel('Data')
ylabel('Model predictions')
legend({'EL model','','OL model',''})
subplot(1,2,2); hold on
plot(Behavior.Prop_OL_ch(iOL,1),prop_OL_ch_from_EL_sub(iOL),'.','Color','#0072BD'); lsline()
plot(Behavior.Prop_OL_ch(iOL,1),prop_OL_ch_from_OL_sub(iOL),'.','Color','#D95319'); lsline()
xlim([0.5 0.9]); ylim([0.1 0.9])
title({'Observational learners'; '(OL choice prop. > 0.5)'})
xlabel('Data')

%print correlations
[r,p] = corr(Behavior.Prop_OL_ch(iEL,1),prop_OL_ch_from_EL_sub(iEL))
[r,p] = corr(Behavior.Prop_OL_ch(iEL,1),prop_OL_ch_from_OL_sub(iEL))
[r,p] = corr(Behavior.Prop_OL_ch(iOL,1),prop_OL_ch_from_EL_sub(iOL))
[r,p] = corr(Behavior.Prop_OL_ch(iOL,1),prop_OL_ch_from_OL_sub(iOL))


%% extract trial-by-trial arbitration weight and plot mean per condition
ntr = 160;
w_bd = nan(n_all, 8);
for s=1:n_all
    params_dynarb = fitRecap.paramRaw.DynArb(s,:);
    subNb = subID_list(s);
    P = table2array(data(data.subNb==subNb,2:end));
    P_pred = generate_choice_DynArb(params_dynarb, P);
    w = P_pred(:,25);
    
    %define uncertainty condition based on key trials, instead of design conditions
    %OL unc = low if past 2 box-token transition consistent; high if not
    %EL unc = low if W-st-W, W-sw-0, 0-st-0, 0-sw-W; high otherwise
    %RM = high if >25, low otherwise
    OL_lu = zeros(ntr,1);
    EL_lu = zeros(ntr,1);
    RM_h = zeros(ntr,1);
    outc_bin = P(:,18); outc_bin(outc_bin>0)=1;
    for t=1:ntr
        if P(t,4)>=3
            if P(t-1,6)==P(t,6)
                OL_lu(t) = 1;
            end
            if (outc_bin(t-2)==outc_bin(t-1) && P(t-2,14)==P(t-1,14)) || (outc_bin(t-2)~=outc_bin(t-1) && P(t-2,14)~=P(t-1,14))
                %same choice, same outcome OR different choice, different outcome
                EL_lu(t) = 1;
            end
        end
        if P(t,3)>=2 && P(t-1,18)>25
            RM_h(t) = 1;
        end
    end
    OL_lu = logical(OL_lu);
    EL_lu = logical(EL_lu);
    RM_h = logical(RM_h);
    
    w_bd(s,:) = [nanmean(w(OL_lu & EL_lu & RM_h)) nanmean(w(OL_lu & EL_lu & ~RM_h)) ...
        nanmean(w(OL_lu & ~EL_lu & RM_h)) nanmean(w(OL_lu & ~EL_lu & ~RM_h)) ...
        nanmean(w(~OL_lu & EL_lu & RM_h)) nanmean(w(~OL_lu & EL_lu & ~RM_h)) ...
        nanmean(w(~OL_lu & ~EL_lu & RM_h)) nanmean(w(~OL_lu & ~EL_lu & ~RM_h))];  
end

figure;
subplot(1,2,1); hold on
b = bar([nanmean(w_bd(:,1:2)); nanmean(w_bd(:,3:4))],0.8,'FaceColor','flat','EdgeColor','k','LineWidth',1);
b(1).CData = [0.9290 0.6940 0.1250]; 
b(2).CData = [0.4940 0.1840 0.5560];
plotSpread(w_bd(:,1:4),'xValues',[0.85 1.15 1.85 2.15],'distributionColors',[0.4 0.4 0.4]); 
errorbar([0.85 1.15 1.85 2.15],nanmean(w_bd(:,1:4)),nanstd(w_bd(:,1:4))/sqrt(n_all),'.k','LineWidth',1.5)
plot([0.5 2.5],[0.5 0.5],'--k')
xticks([1 2])
xticklabels({'Low','High'})
xlabel('EL uncertainty')
ylabel('Arbitration weight (OL vs EL)')
title('LOW OL uncertainty')
subplot(1,2,2); hold on
b = bar([nanmean(w_bd(:,5:6)); nanmean(w_bd(:,7:8))],0.8,'FaceColor','flat','EdgeColor','k','LineWidth',1);
b(1).CData = [0.9290 0.6940 0.1250]; 
b(2).CData = [0.4940 0.1840 0.5560];
plotSpread(w_bd(:,5:8),'xValues',[0.85 1.15 1.85 2.15],'distributionColors',[0.4 0.4 0.4]); 
errorbar([0.85 1.15 1.85 2.15],nanmean(w_bd(:,5:8)),nanstd(w_bd(:,5:8))/sqrt(n_all),'.k','LineWidth',1.5)
plot([0.5 2.5],[0.5 0.5],'--k')
xticks([1 2])
xticklabels({'Low','High'})
xlabel('EL uncertainty')
title('HIGH OL uncertainty')
leg = legend({'High','Low'});
title(leg,'Magnitude')
